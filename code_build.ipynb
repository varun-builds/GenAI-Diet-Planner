{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd3e8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq==0.9.0 (from -r requirements.txt (line 1))\n",
      "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting openai>=1.0.0 (from -r requirements.txt (line 2))\n",
      "  Downloading openai-2.15.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\varun\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (0.21.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=1.0.0->-r requirements.txt (line 2))\n",
      "  Downloading jiter-0.12.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0.0->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq==0.9.0->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\varun\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq==0.9.0->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\varun\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq==0.9.0->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq==0.9.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq==0.9.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq==0.9.0->-r requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\varun\\anaconda3\\lib\\site-packages (from tqdm>4->openai>=1.0.0->-r requirements.txt (line 2)) (0.4.6)\n",
      "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.5 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 71.7/103.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 103.5/103.5 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading openai-2.15.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 22.5 MB/s eta 0:00:00\n",
      "Downloading jiter-0.12.0-cp312-cp312-win_amd64.whl (205 kB)\n",
      "   ---------------------------------------- 0.0/205.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 205.2/205.2 kB 13.0 MB/s eta 0:00:00\n",
      "Installing collected packages: jiter, openai, groq\n",
      "  Attempting uninstall: groq\n",
      "    Found existing installation: groq 1.0.0\n",
      "    Uninstalling groq-1.0.0:\n",
      "      Successfully uninstalled groq-1.0.0\n",
      "Successfully installed groq-0.9.0 jiter-0.12.0 openai-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02ed968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make changes to files\n",
    "git status            # See what changed\n",
    "git add .             # Stage everything\n",
    "git commit -m \"Update diet planner features\"\n",
    "git push origin main  # Push to GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5267556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b71ad53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7b0f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1f26957",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98d8965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3ced006",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a5c8903",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    temperature=0,\n",
    "    stop=None,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1703993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='That‚Äôs music to a data‚Äëscientist‚Äôs ears! üé∂ü§ñ  \\nIf ML were a superhero, it‚Äôd be ‚ÄúCaptain Gradient Descent‚Äù ‚Äì always finding the best path, never taking the easy (or flat) route.  \\n\\nWhat‚Äôs your favorite ML trick? Turning cats into memes with GANs? Teaching a model to predict the perfect pizza topping combo? Let‚Äôs geek out together! üöÄ‚ú®', additional_kwargs={'reasoning_content': 'The user says \"I love Machine Learning.\" We should respond in a fun and witty manner, acknowledging their love for ML, maybe ask about their interests, mention something humorous. Follow developer instruction: fun and witty. No disallowed content.'}, response_metadata={'token_usage': {'completion_tokens': 143, 'prompt_tokens': 92, 'total_tokens': 235, 'completion_time': 0.299748608, 'completion_tokens_details': {'reasoning_tokens': 49}, 'prompt_time': 0.003624132, 'prompt_tokens_details': None, 'queue_time': 0.052496218, 'total_time': 0.30337274}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_8a618bed98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019c05cf-d668-7383-b744-b93cf34e060f-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 92, 'output_tokens': 143, 'total_tokens': 235, 'output_token_details': {'reasoning': 49}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    (\n",
    "        \"system\",\n",
    "        \"You are a helpful assistant. You use fun and witty responses.\",\n",
    "    ),\n",
    "    (\"human\", \"I love Machine Learning.\"),\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a0e4b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That‚Äôs music to a data‚Äëscientist‚Äôs ears! üé∂ü§ñ  \n",
      "If ML were a superhero, it‚Äôd be ‚ÄúCaptain Gradient Descent‚Äù ‚Äì always finding the best path, never taking the easy (or flat) route.  \n",
      "\n",
      "What‚Äôs your favorite ML trick? Turning cats into memes with GANs? Teaching a model to predict the perfect pizza topping combo? Let‚Äôs geek out together! üöÄ‚ú®\n"
     ]
    }
   ],
   "source": [
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e54a74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opendatalab 0.0.10 requires pycryptodome, which is not installed.\n",
      "streamlit 1.32.0 requires protobuf<5,>=3.20, but you have protobuf 5.29.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "pip install -qU duckduckgo-search langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d9ea377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Machine learning & AI news . Date. Machine learning lends a helping 'hand' to prosthetics. Holding an egg requires a gentle touch. here's a list of various AI/ML news sources: TechCrunch AI/ML Section - Offers news , analysis, and insights into the latest developments in AI and machine learning . MIT Technology Review - Covers advancements in AI, machine learning , and emerging technologies. What is machine learning ? Machine learning is the subset of artificial intelligence (AI) focused on algorithms that can ‚Äú learn ‚Äù the patterns of training data and, subsequently, make accurate inferences about new data. If a machine can coordinate multiple tasks, fewer humans are needed to manage them. AI turns out to be remarkably good at exactly the kind of work that employed millions of people: following procedures, coordinating handoffs between departments, and navigating bureaucratic complexity. You are the spark. Get the latest AI news , courses, events, and insights from Andrew Ng and other AI leaders.Build a foundation of machine learning and AI skills, and understand how to apply them in the real world.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search.invoke(\"what is the latest news about Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "647b13b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = search.invoke(\"what is todays date?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60cc0ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 month ago - Today‚Äôs date in numbers yyyy/mm/dd is 2026/01/19 May 7, 2025 - Sun, 18 January 2026 Do you ever find yourself confused about the date? With so numerous different ways of writing dates, it\\'s easy to get mixed up. In this composition, we\\'ll take a close look at some of the most common date formats and answer the question,\" What is Today\\'s date?\" What is ... August 4, 2025 - The simplest way to see the date today and stay on top of your schedule. With the varying conventions for writing the date, miscommunication can easily occur. A date written as 03/04/2024 could refer to two completely different dates: ... This ambiguity can lead to missed deadlines, incorrect records, and general disorder. The best practice, especially in international communications, is to avoid numbers alone and write out the month‚Äôs name. 3 weeks ago - As of now, it is November 12th, 2025 . Now let‚Äôs break that down into numbers‚Äîbecause dates can be a bit tricky depending on where you are in the world. In the United States, we typically write it as MM-DD-YYYY: 11-12-2025 or 11/12/2025. 1 week ago - Display Today\\'s date of the Hijri and the Gregorian day in the Hijri and Gregorian calendar site. Today\\'s date is updated automatically every day.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = DuckDuckGoSearchRun()\n",
    "search.invoke(\"what is todays date?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87cadd7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Result: snippet: Get to know what date it is today based on your current location. What Is the Date Today In Numbers? The current date depends on the region you are currently residing in. The most common date formats include, title: What Is Today ‚Äôs Date ?, link: https://thetimecalculator.org/today-date, snippet: What is today 's date ? Today ‚Äôs date in numbers and slashes. When writing the date by numbers only, you can separate them by using a hyphen (-), a slash (/), or a dot (.), title: Today ‚Äôs date in numbers ¬ª Today - date .com, link: https://today-date.com/, snippet: what is today 's date ? calculate yards of concrete. how long until 3:30?For instance, if the current date is November 1st, then the result might look like this: Graphic showing the formula for Google Sheets or Microsoft Excel to calculate the current date ., title: What Is Today 's Date ? - Inch Calculator, link: https://www.inchcalculator.com/what-is-todays-date/, snippet: Today 's Date is your one-stop destination to master time tracking. We provide accurate, real-time updates on the current date and time and many other useful information., title: What is the date today | Today 's Date, link: https://www.datetoday.info/\n"
     ]
    }
   ],
   "source": [
    "print(\"Raw Result:\",result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb064944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc94d1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a9c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4ba523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7d15858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opendatalab 0.0.10 requires pycryptodome, which is not installed.\n",
      "streamlit 1.32.0 requires protobuf<5,>=3.20, but you have protobuf 5.29.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq ddgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10f86ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'snippet: 6 days ago ¬∑ New ‚Äúbiomimetic‚Äù model of brain circuits and function at multiple scales produced naturalistic dynamics and learning , and even identified curious behavior by some neurons. New research detects hidden evidence of mistaken correlations ‚Äî and provides a method to improve accuracy., title: Machine learning | MIT News | Massachusetts Institute of ..., link: https://news.mit.edu/topic/machine-learning, snippet: Read full articles, watch videos, browse thousands of titles and more on the \" Machine learning \" topic with Google News., title: Google News - Machine learning - Latest, link: https://news.google.com/topics/CAAqIggKIhxDQkFTRHdvSkwyMHZNREZvZVdoZkVnSmxiaWdBUAE, snippet: Read the latest on artificial intelligence and machine learning tech, the companies that are building them, and the ethical issues AI raises today., title: AI News & Artificial Intelligence | TechCrunch, link: https://techcrunch.com/category/artificial-intelligence/, snippet: 4 days ago ¬∑ MIT researchers have identified significant examples of machine - learning model failure when those models are applied to data other than what they were trained on, raising questions about the need to test whenever a model ..., title: News on Artificial Intelligence and Machine Learning, link: https://techxplore.com/machine-learning-ai-news/'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "search = DuckDuckGoSearchResults()\n",
    "\n",
    "search.invoke(\"what is the latest news about Machine Learning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76613437",
   "metadata": {},
   "source": [
    "## Example 6: Integrating Search as a Tool for Your Agent\n",
    "\n",
    "Add web search capability to your diet planner agent so it can fetch real-time nutritional information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d83f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Create a search tool that your agent can use\n",
    "search_runner = DuckDuckGoSearchRun()\n",
    "\n",
    "@tool\n",
    "def search_nutrition_info(query: str) -> str:\n",
    "    \"\"\"Search for nutritional information about food items or diet topics.\"\"\"\n",
    "    try:\n",
    "        results = search_runner.invoke(query)\n",
    "        # Clean up results\n",
    "        lines = results.split('\\n')\n",
    "        cleaned = [line.strip() for line in lines if line.strip() and len(line.strip()) > 10]\n",
    "        return '\\n'.join(cleaned[:3])  # Return top 3 results\n",
    "    except Exception as e:\n",
    "        return f\"Search failed: {str(e)}\"\n",
    "\n",
    "# Define your existing tools\n",
    "@tool\n",
    "def calculate_calories(meal: str, portion_size: str) -> str:\n",
    "    \"\"\"Calculate calories for a given meal and portion size.\"\"\"\n",
    "    meal_calories = {\n",
    "        \"chicken breast\": 165,\n",
    "        \"rice\": 206,\n",
    "        \"broccoli\": 34,\n",
    "        \"salmon\": 280,\n",
    "        \"apple\": 95\n",
    "    }\n",
    "    calories = meal_calories.get(meal.lower(), 0)\n",
    "    return f\"{meal} ({portion_size}) contains approximately {calories} calories per 100g\"\n",
    "\n",
    "@tool\n",
    "def get_nutritional_info(food_item: str) -> str:\n",
    "    \"\"\"Get nutritional information for a food item including protein, carbs, and fat.\"\"\"\n",
    "    nutrition_db = {\n",
    "        \"chicken breast\": \"Protein: 31g, Carbs: 0g, Fat: 3.6g (per 100g)\",\n",
    "        \"rice\": \"Protein: 2.7g, Carbs: 28g, Fat: 0.3g (per 100g)\",\n",
    "        \"broccoli\": \"Protein: 2.8g, Carbs: 7g, Fat: 0.4g (per 100g)\",\n",
    "        \"salmon\": \"Protein: 25g, Carbs: 0g, Fat: 13g (per 100g)\"\n",
    "    }\n",
    "    return nutrition_db.get(food_item.lower(), \"Food item not found in database\")\n",
    "\n",
    "# Create agent with search included\n",
    "llm = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "\n",
    "# Include search tool in your toolset\n",
    "tools_with_search = [calculate_calories, get_nutritional_info, search_nutrition_info]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent = create_react_agent(llm, tools_with_search, prompt)\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, \n",
    "    tools=tools_with_search, \n",
    "    verbose=True,\n",
    "    max_iterations=10\n",
    ")\n",
    "\n",
    "# Test: Agent will decide to use search for questions it doesn't have data for\n",
    "print(\"=== Agent with Search Tool ===\\n\")\n",
    "result = agent_executor.invoke({\n",
    "    \"input\": \"What is the nutritional value of quinoa and how does it compare to rice?\"\n",
    "})\n",
    "print(\"\\nFinal Response:\", result[\"output\"])\n",
    "\n",
    "# Test 2: Agent uses local data when available\n",
    "print(\"\\n=== Agent Uses Local Data ===\\n\")\n",
    "result2 = agent_executor.invoke({\n",
    "    \"input\": \"Tell me about chicken breast nutrition and then search for new diet trends\"\n",
    "})\n",
    "print(\"\\nFinal Response:\", result2[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9350bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0463c4bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037400a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb1e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e466f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9bc4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1cf44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884387f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e93d29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af82ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d83378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c37575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeac5a53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f06ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d2ed40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cd069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe55bf21",
   "metadata": {},
   "source": [
    "# LangChain Agents Examples\n",
    "\n",
    "LangChain agents allow AI models to interact with tools and take actions based on model decisions. Agents can decide which tools to use and in what sequence to accomplish a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102e1ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opendatalab 0.0.10 requires pycryptodome, which is not installed.\n",
      "autogluon-core 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.0 which is incompatible.\n",
      "autogluon-multimodal 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.0 which is incompatible.\n",
      "autogluon-tabular 1.2 requires scikit-learn<1.5.3,>=1.4.0, but you have scikit-learn 1.6.0 which is incompatible.\n",
      "streamlit 1.32.0 requires protobuf<5,>=3.20, but you have protobuf 5.29.1 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "# Install LangChain dependencies\n",
    "!pip install langchain langchain-community langchain-core python-dotenv -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ecebf8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'create_react_agent' from 'langchain.agents' (c:\\Users\\varun\\anaconda3\\Lib\\site-packages\\langchain\\agents\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tool\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_react_agent, AgentExecutor\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hub\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_groq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGroq\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'create_react_agent' from 'langchain.agents' (c:\\Users\\varun\\anaconda3\\Lib\\site-packages\\langchain\\agents\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0fa20",
   "metadata": {},
   "source": [
    "## Example 1: Simple Tool Definition and Agent Setup\n",
    "\n",
    "Basic example showing how to define tools and create an agent that can use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f083b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Define some simple tools\n",
    "@tool\n",
    "def calculate_calories(meal: str, portion_size: str) -> str:\n",
    "    \"\"\"Calculate calories for a given meal and portion size.\"\"\"\n",
    "    # Simplified example\n",
    "    meal_calories = {\n",
    "        \"chicken breast\": 165,\n",
    "        \"rice\": 206,\n",
    "        \"broccoli\": 34,\n",
    "        \"salmon\": 280,\n",
    "        \"apple\": 95\n",
    "    }\n",
    "    calories = meal_calories.get(meal.lower(), 0)\n",
    "    return f\"{meal} ({portion_size}) contains approximately {calories} calories per 100g\"\n",
    "\n",
    "@tool\n",
    "def get_nutritional_info(food_item: str) -> str:\n",
    "    \"\"\"Get nutritional information for a food item including protein, carbs, and fat.\"\"\"\n",
    "    nutrition_db = {\n",
    "        \"chicken breast\": \"Protein: 31g, Carbs: 0g, Fat: 3.6g (per 100g)\",\n",
    "        \"rice\": \"Protein: 2.7g, Carbs: 28g, Fat: 0.3g (per 100g)\",\n",
    "        \"broccoli\": \"Protein: 2.8g, Carbs: 7g, Fat: 0.4g (per 100g)\",\n",
    "        \"salmon\": \"Protein: 25g, Carbs: 0g, Fat: 13g (per 100g)\"\n",
    "    }\n",
    "    return nutrition_db.get(food_item.lower(), \"Food item not found in database\")\n",
    "\n",
    "# Create the agent\n",
    "llm = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "tools = [calculate_calories, get_nutritional_info]\n",
    "\n",
    "# Get the prompt template from LangChain hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Create the agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Test the agent\n",
    "result = agent_executor.invoke({\"input\": \"What are the calories and nutritional info for chicken breast?\"})\n",
    "print(\"Agent Response:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a1621",
   "metadata": {},
   "source": [
    "## Example 2: Agent with Multiple Function Tools\n",
    "\n",
    "Agent that can call multiple tools to answer diet planning questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_dietary_restrictions(restriction: str) -> str:\n",
    "    \"\"\"Check if a food item is suitable for common dietary restrictions.\"\"\"\n",
    "    restrictions_db = {\n",
    "        \"vegetarian\": [\"chicken\", \"salmon\", \"beef\"],  # These are NOT vegetarian\n",
    "        \"gluten-free\": [\"bread\", \"pasta\", \"cereal\"],  # These contain gluten\n",
    "        \"vegan\": [\"chicken\", \"salmon\", \"beef\", \"eggs\", \"milk\"],  # Animal products\n",
    "        \"low-carb\": [\"rice\", \"bread\", \"pasta\"]  # High carb foods\n",
    "    }\n",
    "    return f\"Foods to avoid for {restriction}: {', '.join(restrictions_db.get(restriction.lower(), []))}\"\n",
    "\n",
    "@tool\n",
    "def suggest_meal_plan(calories_target: int, diet_type: str) -> str:\n",
    "    \"\"\"Suggest a meal plan based on calorie target and diet type.\"\"\"\n",
    "    meal_suggestions = {\n",
    "        \"vegetarian\": [\"Grilled vegetables with paneer\", \"Lentil curry\", \"Vegetable stir-fry\"],\n",
    "        \"high-protein\": [\"Grilled chicken breast\", \"Salmon fillet\", \"Egg whites\"],\n",
    "        \"low-carb\": [\"Grilled vegetables\", \"Salads with olive oil\", \"Meat dishes\"]\n",
    "    }\n",
    "    suggestions = meal_suggestions.get(diet_type.lower(), [\"Balanced meal\"])\n",
    "    return f\"For {calories_target} calories and {diet_type} diet, suggested meals: {', '.join(suggestions)}\"\n",
    "\n",
    "# Create an enhanced agent with more tools\n",
    "llm = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "tools_extended = [calculate_calories, get_nutritional_info, check_dietary_restrictions, suggest_meal_plan]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent_extended = create_react_agent(llm, tools_extended, prompt)\n",
    "agent_executor_extended = AgentExecutor(agent=agent_extended, tools=tools_extended, verbose=True)\n",
    "\n",
    "# Test with a more complex query\n",
    "result = agent_executor_extended.invoke({\n",
    "    \"input\": \"I need a vegetarian meal plan for 2000 calories. What meals do you suggest and what should I avoid?\"\n",
    "})\n",
    "print(\"\\nAgent Response:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aabfad",
   "metadata": {},
   "source": [
    "## Example 3: Agent with Memory (Conversation History)\n",
    "\n",
    "Agent that remembers previous interactions in a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0debc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "# Create memory for conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Initialize agent with memory using the deprecated but still functional approach\n",
    "llm_with_memory = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "\n",
    "# You can also use a simpler approach with conversation buffer\n",
    "conversation_history = []\n",
    "\n",
    "def add_to_history(role: str, content: str):\n",
    "    \"\"\"Helper to add messages to conversation history.\"\"\"\n",
    "    conversation_history.append({\"role\": role, \"content\": content})\n",
    "\n",
    "# Simulate multi-turn conversation\n",
    "print(\"=== Multi-turn Conversation Example ===\\n\")\n",
    "\n",
    "# Turn 1\n",
    "user_input_1 = \"I'm trying to gain muscle. What's a good daily calorie intake for muscle building?\"\n",
    "print(f\"User: {user_input_1}\")\n",
    "add_to_history(\"user\", user_input_1)\n",
    "\n",
    "# Agent processes with context\n",
    "response_1 = agent_executor_extended.invoke({\"input\": user_input_1})\n",
    "print(f\"Agent: {response_1['output']}\\n\")\n",
    "add_to_history(\"assistant\", response_1['output'])\n",
    "\n",
    "# Turn 2 - Using conversation history context\n",
    "user_input_2 = \"What are the top 3 high-protein foods I should include?\"\n",
    "print(f\"User: {user_input_2}\")\n",
    "add_to_history(\"user\", user_input_2)\n",
    "\n",
    "response_2 = agent_executor_extended.invoke({\"input\": user_input_2})\n",
    "print(f\"Agent: {response_2['output']}\\n\")\n",
    "add_to_history(\"assistant\", response_2['output'])\n",
    "\n",
    "# Print conversation summary\n",
    "print(\"\\n=== Conversation History ===\")\n",
    "for msg in conversation_history:\n",
    "    print(f\"{msg['role'].upper()}: {msg['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c06c7a",
   "metadata": {},
   "source": [
    "## Example 4: Custom Agent with Error Handling\n",
    "\n",
    "Agent with built-in error handling and input validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def validate_and_calculate_daily_intake(age: int, weight: float, activity_level: str) -> str:\n",
    "    \"\"\"Calculate daily caloric needs based on user parameters with validation.\"\"\"\n",
    "    try:\n",
    "        if not (1 <= age <= 120):\n",
    "            return \"Error: Age must be between 1 and 120\"\n",
    "        if not (10 <= weight <= 500):\n",
    "            return \"Error: Weight must be between 10 and 500 kg\"\n",
    "        \n",
    "        valid_activities = [\"sedentary\", \"lightly_active\", \"moderately_active\", \"very_active\"]\n",
    "        if activity_level.lower() not in valid_activities:\n",
    "            return f\"Error: Activity level must be one of {valid_activities}\"\n",
    "        \n",
    "        # Simplified calculation (Basal Metabolic Rate approximation)\n",
    "        bmr = 10 * weight + 6.25 * age - 5\n",
    "        activity_multipliers = {\n",
    "            \"sedentary\": 1.2,\n",
    "            \"lightly_active\": 1.375,\n",
    "            \"moderately_active\": 1.55,\n",
    "            \"very_active\": 1.725\n",
    "        }\n",
    "        \n",
    "        tdee = bmr * activity_multipliers[activity_level.lower()]\n",
    "        return f\"Based on age {age}, weight {weight}kg, and {activity_level} activity: Daily caloric needs = {tdee:.0f} calories\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "# Create robust agent with error handling\n",
    "llm_robust = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "tools_robust = [validate_and_calculate_daily_intake, get_nutritional_info, suggest_meal_plan]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent_robust = create_react_agent(llm_robust, tools_robust, prompt)\n",
    "agent_executor_robust = AgentExecutor(\n",
    "    agent=agent_robust, \n",
    "    tools=tools_robust, \n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")\n",
    "\n",
    "# Test with valid input\n",
    "print(\"=== Test with Valid Input ===\")\n",
    "result = agent_executor_robust.invoke({\n",
    "    \"input\": \"I'm 30 years old, weigh 75kg, and have a moderately active lifestyle. What's my daily caloric need?\"\n",
    "})\n",
    "print(f\"Result: {result['output']}\\n\")\n",
    "\n",
    "# Test with invalid input\n",
    "print(\"=== Test with Invalid Input ===\")\n",
    "try:\n",
    "    result = agent_executor_robust.invoke({\n",
    "        \"input\": \"I'm 200 years old and weigh 5kg - what should I eat?\"\n",
    "    })\n",
    "    print(f\"Result: {result['output']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Agent handled error gracefully: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4c5a1",
   "metadata": {},
   "source": [
    "## Example 5: Agent Chain - Sequential Tool Execution\n",
    "\n",
    "Agent that chains multiple tools together in sequence to solve complex problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dabe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "@tool\n",
    "def compile_meal_prep_guide(meal_name: str, servings: int) -> str:\n",
    "    \"\"\"Create a meal prep guide with ingredients and instructions.\"\"\"\n",
    "    meal_guides = {\n",
    "        \"grilled chicken breast\": {\n",
    "            \"ingredients\": [\"Chicken breast\", \"Olive oil\", \"Salt\", \"Pepper\"],\n",
    "            \"instructions\": \"Season chicken, grill for 6-7 minutes per side at 180¬∞C\",\n",
    "            \"prep_time\": \"15 minutes\"\n",
    "        },\n",
    "        \"rice and beans\": {\n",
    "            \"ingredients\": [\"Brown rice\", \"Black beans\", \"Onion\", \"Garlic\"],\n",
    "            \"instructions\": \"Cook rice for 30 minutes, simmer beans for 45 minutes, combine\",\n",
    "            \"prep_time\": \"50 minutes\"\n",
    "        },\n",
    "        \"vegetable stir-fry\": {\n",
    "            \"ingredients\": [\"Mixed vegetables\", \"Soy sauce\", \"Garlic\", \"Ginger\"],\n",
    "            \"instructions\": \"Heat wok, stir-fry vegetables for 5-7 minutes on high heat\",\n",
    "            \"prep_time\": \"20 minutes\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    guide = meal_guides.get(meal_name.lower(), None)\n",
    "    if guide:\n",
    "        return f\"Meal: {meal_name}\\nServings: {servings}\\nIngredients: {', '.join(guide['ingredients'])}\\nInstructions: {guide['instructions']}\\nPrep Time: {guide['prep_time']}\"\n",
    "    return f\"Meal guide for '{meal_name}' not found in database\"\n",
    "\n",
    "# Create a specialized agent for meal planning\n",
    "llm_meal_planner = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "tools_meal_planner = [\n",
    "    validate_and_calculate_daily_intake,\n",
    "    get_nutritional_info,\n",
    "    suggest_meal_plan,\n",
    "    compile_meal_prep_guide\n",
    "]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent_meal_planner = create_react_agent(llm_meal_planner, tools_meal_planner, prompt)\n",
    "agent_executor_meal_planner = AgentExecutor(\n",
    "    agent=agent_meal_planner, \n",
    "    tools=tools_meal_planner, \n",
    "    verbose=True,\n",
    "    max_iterations=15\n",
    ")\n",
    "\n",
    "# Complex query that requires multiple tools\n",
    "print(\"=== Complex Multi-Step Agent Query ===\\n\")\n",
    "result = agent_executor_meal_planner.invoke({\n",
    "    \"input\": \"I need a high-protein meal plan. First calculate my daily caloric needs (I'm 25, weigh 70kg, very active), then suggest high-protein meals, and finally give me a prep guide for grilled chicken breast for 4 servings.\"\n",
    "})\n",
    "print(f\"\\nFinal Result: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca0727",
   "metadata": {},
   "source": [
    "## Key Concepts Summary\n",
    "\n",
    "**What are LangChain Agents?**\n",
    "- Agents use an LLM to determine which tools to call and in what order\n",
    "- They follow a reasoning loop: Think ‚Üí Act ‚Üí Observe ‚Üí Repeat\n",
    "- Excellent for complex multi-step tasks that require decision-making\n",
    "\n",
    "**When to use Agents:**\n",
    "- Multi-tool workflows where tool selection depends on user input\n",
    "- Tasks requiring reasoning about tool sequencing\n",
    "- Problems where the solution path isn't predetermined\n",
    "- Interactive applications needing dynamic tool usage\n",
    "\n",
    "**Common Agent Types:**\n",
    "- **ReAct Agent**: Reason + Act pattern (recommended)\n",
    "- **OpenAI Functions Agent**: For models with function-calling capabilities\n",
    "- **Conversational Agent**: For multi-turn dialogue with memory\n",
    "\n",
    "**Best Practices:**\n",
    "1. Define clear tool descriptions - agents rely on these to decide tool usage\n",
    "2. Include input validation in tools to prevent errors\n",
    "3. Use `max_iterations` to prevent infinite loops\n",
    "4. Enable `verbose=True` during development for debugging\n",
    "5. Handle parsing errors gracefully\n",
    "6. Keep tools focused and single-purpose\n",
    "7. Provide example outputs in tool descriptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
