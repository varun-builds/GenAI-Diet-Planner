{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd3e8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq==0.9.0 (from -r requirements.txt (line 1))\n",
      "  Downloading groq-0.9.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting openai>=1.0.0 (from -r requirements.txt (line 2))\n",
      "  Downloading openai-2.15.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\varun\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (0.21.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (2.10.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from groq==0.9.0->-r requirements.txt (line 1)) (4.15.0)\n",
      "Collecting jiter<1,>=0.10.0 (from openai>=1.0.0->-r requirements.txt (line 2))\n",
      "  Downloading jiter-0.12.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from openai>=1.0.0->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->groq==0.9.0->-r requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: certifi in c:\\users\\varun\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq==0.9.0->-r requirements.txt (line 1)) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\varun\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->groq==0.9.0->-r requirements.txt (line 1)) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\varun\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq==0.9.0->-r requirements.txt (line 1)) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq==0.9.0->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\varun\\appdata\\roaming\\python\\python312\\site-packages (from pydantic<3,>=1.9.0->groq==0.9.0->-r requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\varun\\anaconda3\\lib\\site-packages (from tqdm>4->openai>=1.0.0->-r requirements.txt (line 2)) (0.4.6)\n",
      "Downloading groq-0.9.0-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.5 kB ? eta -:--:--\n",
      "   --------------------------- ------------ 71.7/103.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 103.5/103.5 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading openai-2.15.0-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 22.5 MB/s eta 0:00:00\n",
      "Downloading jiter-0.12.0-cp312-cp312-win_amd64.whl (205 kB)\n",
      "   ---------------------------------------- 0.0/205.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 205.2/205.2 kB 13.0 MB/s eta 0:00:00\n",
      "Installing collected packages: jiter, openai, groq\n",
      "  Attempting uninstall: groq\n",
      "    Found existing installation: groq 1.0.0\n",
      "    Uninstalling groq-1.0.0:\n",
      "      Successfully uninstalled groq-1.0.0\n",
      "Successfully installed groq-0.9.0 jiter-0.12.0 openai-2.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71ad53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7b0f769",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1f26957",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Groq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98d8965c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=[\n",
    "      {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\n",
    "      }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    stream=True,\n",
    "    stop=None\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ced006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe55bf21",
   "metadata": {},
   "source": [
    "# LangChain Agents Examples\n",
    "\n",
    "LangChain agents allow AI models to interact with tools and take actions based on model decisions. Agents can decide which tools to use and in what sequence to accomplish a task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102e1ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LangChain dependencies\n",
    "!pip install langchain langchain-community langchain-core python-dotenv -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af0fa20",
   "metadata": {},
   "source": [
    "## Example 1: Simple Tool Definition and Agent Setup\n",
    "\n",
    "Basic example showing how to define tools and create an agent that can use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f083b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain_core.tools import Tool\n",
    "from langchain.agents import create_react_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "# Define some simple tools\n",
    "@tool\n",
    "def calculate_calories(meal: str, portion_size: str) -> str:\n",
    "    \"\"\"Calculate calories for a given meal and portion size.\"\"\"\n",
    "    # Simplified example\n",
    "    meal_calories = {\n",
    "        \"chicken breast\": 165,\n",
    "        \"rice\": 206,\n",
    "        \"broccoli\": 34,\n",
    "        \"salmon\": 280,\n",
    "        \"apple\": 95\n",
    "    }\n",
    "    calories = meal_calories.get(meal.lower(), 0)\n",
    "    return f\"{meal} ({portion_size}) contains approximately {calories} calories per 100g\"\n",
    "\n",
    "@tool\n",
    "def get_nutritional_info(food_item: str) -> str:\n",
    "    \"\"\"Get nutritional information for a food item including protein, carbs, and fat.\"\"\"\n",
    "    nutrition_db = {\n",
    "        \"chicken breast\": \"Protein: 31g, Carbs: 0g, Fat: 3.6g (per 100g)\",\n",
    "        \"rice\": \"Protein: 2.7g, Carbs: 28g, Fat: 0.3g (per 100g)\",\n",
    "        \"broccoli\": \"Protein: 2.8g, Carbs: 7g, Fat: 0.4g (per 100g)\",\n",
    "        \"salmon\": \"Protein: 25g, Carbs: 0g, Fat: 13g (per 100g)\"\n",
    "    }\n",
    "    return nutrition_db.get(food_item.lower(), \"Food item not found in database\")\n",
    "\n",
    "# Create the agent\n",
    "llm = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "tools = [calculate_calories, get_nutritional_info]\n",
    "\n",
    "# Get the prompt template from LangChain hub\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "\n",
    "# Create the agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Test the agent\n",
    "result = agent_executor.invoke({\"input\": \"What are the calories and nutritional info for chicken breast?\"})\n",
    "print(\"Agent Response:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a1621",
   "metadata": {},
   "source": [
    "## Example 2: Agent with Multiple Function Tools\n",
    "\n",
    "Agent that can call multiple tools to answer diet planning questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9d904f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def check_dietary_restrictions(restriction: str) -> str:\n",
    "    \"\"\"Check if a food item is suitable for common dietary restrictions.\"\"\"\n",
    "    restrictions_db = {\n",
    "        \"vegetarian\": [\"chicken\", \"salmon\", \"beef\"],  # These are NOT vegetarian\n",
    "        \"gluten-free\": [\"bread\", \"pasta\", \"cereal\"],  # These contain gluten\n",
    "        \"vegan\": [\"chicken\", \"salmon\", \"beef\", \"eggs\", \"milk\"],  # Animal products\n",
    "        \"low-carb\": [\"rice\", \"bread\", \"pasta\"]  # High carb foods\n",
    "    }\n",
    "    return f\"Foods to avoid for {restriction}: {', '.join(restrictions_db.get(restriction.lower(), []))}\"\n",
    "\n",
    "@tool\n",
    "def suggest_meal_plan(calories_target: int, diet_type: str) -> str:\n",
    "    \"\"\"Suggest a meal plan based on calorie target and diet type.\"\"\"\n",
    "    meal_suggestions = {\n",
    "        \"vegetarian\": [\"Grilled vegetables with paneer\", \"Lentil curry\", \"Vegetable stir-fry\"],\n",
    "        \"high-protein\": [\"Grilled chicken breast\", \"Salmon fillet\", \"Egg whites\"],\n",
    "        \"low-carb\": [\"Grilled vegetables\", \"Salads with olive oil\", \"Meat dishes\"]\n",
    "    }\n",
    "    suggestions = meal_suggestions.get(diet_type.lower(), [\"Balanced meal\"])\n",
    "    return f\"For {calories_target} calories and {diet_type} diet, suggested meals: {', '.join(suggestions)}\"\n",
    "\n",
    "# Create an enhanced agent with more tools\n",
    "llm = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "tools_extended = [calculate_calories, get_nutritional_info, check_dietary_restrictions, suggest_meal_plan]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent_extended = create_react_agent(llm, tools_extended, prompt)\n",
    "agent_executor_extended = AgentExecutor(agent=agent_extended, tools=tools_extended, verbose=True)\n",
    "\n",
    "# Test with a more complex query\n",
    "result = agent_executor_extended.invoke({\n",
    "    \"input\": \"I need a vegetarian meal plan for 2000 calories. What meals do you suggest and what should I avoid?\"\n",
    "})\n",
    "print(\"\\nAgent Response:\", result[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aabfad",
   "metadata": {},
   "source": [
    "## Example 3: Agent with Memory (Conversation History)\n",
    "\n",
    "Agent that remembers previous interactions in a conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0debc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "# Create memory for conversation history\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "# Initialize agent with memory using the deprecated but still functional approach\n",
    "llm_with_memory = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "\n",
    "# You can also use a simpler approach with conversation buffer\n",
    "conversation_history = []\n",
    "\n",
    "def add_to_history(role: str, content: str):\n",
    "    \"\"\"Helper to add messages to conversation history.\"\"\"\n",
    "    conversation_history.append({\"role\": role, \"content\": content})\n",
    "\n",
    "# Simulate multi-turn conversation\n",
    "print(\"=== Multi-turn Conversation Example ===\\n\")\n",
    "\n",
    "# Turn 1\n",
    "user_input_1 = \"I'm trying to gain muscle. What's a good daily calorie intake for muscle building?\"\n",
    "print(f\"User: {user_input_1}\")\n",
    "add_to_history(\"user\", user_input_1)\n",
    "\n",
    "# Agent processes with context\n",
    "response_1 = agent_executor_extended.invoke({\"input\": user_input_1})\n",
    "print(f\"Agent: {response_1['output']}\\n\")\n",
    "add_to_history(\"assistant\", response_1['output'])\n",
    "\n",
    "# Turn 2 - Using conversation history context\n",
    "user_input_2 = \"What are the top 3 high-protein foods I should include?\"\n",
    "print(f\"User: {user_input_2}\")\n",
    "add_to_history(\"user\", user_input_2)\n",
    "\n",
    "response_2 = agent_executor_extended.invoke({\"input\": user_input_2})\n",
    "print(f\"Agent: {response_2['output']}\\n\")\n",
    "add_to_history(\"assistant\", response_2['output'])\n",
    "\n",
    "# Print conversation summary\n",
    "print(\"\\n=== Conversation History ===\")\n",
    "for msg in conversation_history:\n",
    "    print(f\"{msg['role'].upper()}: {msg['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c06c7a",
   "metadata": {},
   "source": [
    "## Example 4: Custom Agent with Error Handling\n",
    "\n",
    "Agent with built-in error handling and input validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c6a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def validate_and_calculate_daily_intake(age: int, weight: float, activity_level: str) -> str:\n",
    "    \"\"\"Calculate daily caloric needs based on user parameters with validation.\"\"\"\n",
    "    try:\n",
    "        if not (1 <= age <= 120):\n",
    "            return \"Error: Age must be between 1 and 120\"\n",
    "        if not (10 <= weight <= 500):\n",
    "            return \"Error: Weight must be between 10 and 500 kg\"\n",
    "        \n",
    "        valid_activities = [\"sedentary\", \"lightly_active\", \"moderately_active\", \"very_active\"]\n",
    "        if activity_level.lower() not in valid_activities:\n",
    "            return f\"Error: Activity level must be one of {valid_activities}\"\n",
    "        \n",
    "        # Simplified calculation (Basal Metabolic Rate approximation)\n",
    "        bmr = 10 * weight + 6.25 * age - 5\n",
    "        activity_multipliers = {\n",
    "            \"sedentary\": 1.2,\n",
    "            \"lightly_active\": 1.375,\n",
    "            \"moderately_active\": 1.55,\n",
    "            \"very_active\": 1.725\n",
    "        }\n",
    "        \n",
    "        tdee = bmr * activity_multipliers[activity_level.lower()]\n",
    "        return f\"Based on age {age}, weight {weight}kg, and {activity_level} activity: Daily caloric needs = {tdee:.0f} calories\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error in calculation: {str(e)}\"\n",
    "\n",
    "# Create robust agent with error handling\n",
    "llm_robust = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "tools_robust = [validate_and_calculate_daily_intake, get_nutritional_info, suggest_meal_plan]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent_robust = create_react_agent(llm_robust, tools_robust, prompt)\n",
    "agent_executor_robust = AgentExecutor(\n",
    "    agent=agent_robust, \n",
    "    tools=tools_robust, \n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True,\n",
    "    max_iterations=10\n",
    ")\n",
    "\n",
    "# Test with valid input\n",
    "print(\"=== Test with Valid Input ===\")\n",
    "result = agent_executor_robust.invoke({\n",
    "    \"input\": \"I'm 30 years old, weigh 75kg, and have a moderately active lifestyle. What's my daily caloric need?\"\n",
    "})\n",
    "print(f\"Result: {result['output']}\\n\")\n",
    "\n",
    "# Test with invalid input\n",
    "print(\"=== Test with Invalid Input ===\")\n",
    "try:\n",
    "    result = agent_executor_robust.invoke({\n",
    "        \"input\": \"I'm 200 years old and weigh 5kg - what should I eat?\"\n",
    "    })\n",
    "    print(f\"Result: {result['output']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Agent handled error gracefully: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4c5a1",
   "metadata": {},
   "source": [
    "## Example 5: Agent Chain - Sequential Tool Execution\n",
    "\n",
    "Agent that chains multiple tools together in sequence to solve complex problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482dabe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent\n",
    "\n",
    "@tool\n",
    "def compile_meal_prep_guide(meal_name: str, servings: int) -> str:\n",
    "    \"\"\"Create a meal prep guide with ingredients and instructions.\"\"\"\n",
    "    meal_guides = {\n",
    "        \"grilled chicken breast\": {\n",
    "            \"ingredients\": [\"Chicken breast\", \"Olive oil\", \"Salt\", \"Pepper\"],\n",
    "            \"instructions\": \"Season chicken, grill for 6-7 minutes per side at 180°C\",\n",
    "            \"prep_time\": \"15 minutes\"\n",
    "        },\n",
    "        \"rice and beans\": {\n",
    "            \"ingredients\": [\"Brown rice\", \"Black beans\", \"Onion\", \"Garlic\"],\n",
    "            \"instructions\": \"Cook rice for 30 minutes, simmer beans for 45 minutes, combine\",\n",
    "            \"prep_time\": \"50 minutes\"\n",
    "        },\n",
    "        \"vegetable stir-fry\": {\n",
    "            \"ingredients\": [\"Mixed vegetables\", \"Soy sauce\", \"Garlic\", \"Ginger\"],\n",
    "            \"instructions\": \"Heat wok, stir-fry vegetables for 5-7 minutes on high heat\",\n",
    "            \"prep_time\": \"20 minutes\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    guide = meal_guides.get(meal_name.lower(), None)\n",
    "    if guide:\n",
    "        return f\"Meal: {meal_name}\\nServings: {servings}\\nIngredients: {', '.join(guide['ingredients'])}\\nInstructions: {guide['instructions']}\\nPrep Time: {guide['prep_time']}\"\n",
    "    return f\"Meal guide for '{meal_name}' not found in database\"\n",
    "\n",
    "# Create a specialized agent for meal planning\n",
    "llm_meal_planner = ChatGroq(model=\"mixtral-8x7b-32768\", temperature=0)\n",
    "tools_meal_planner = [\n",
    "    validate_and_calculate_daily_intake,\n",
    "    get_nutritional_info,\n",
    "    suggest_meal_plan,\n",
    "    compile_meal_prep_guide\n",
    "]\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "agent_meal_planner = create_react_agent(llm_meal_planner, tools_meal_planner, prompt)\n",
    "agent_executor_meal_planner = AgentExecutor(\n",
    "    agent=agent_meal_planner, \n",
    "    tools=tools_meal_planner, \n",
    "    verbose=True,\n",
    "    max_iterations=15\n",
    ")\n",
    "\n",
    "# Complex query that requires multiple tools\n",
    "print(\"=== Complex Multi-Step Agent Query ===\\n\")\n",
    "result = agent_executor_meal_planner.invoke({\n",
    "    \"input\": \"I need a high-protein meal plan. First calculate my daily caloric needs (I'm 25, weigh 70kg, very active), then suggest high-protein meals, and finally give me a prep guide for grilled chicken breast for 4 servings.\"\n",
    "})\n",
    "print(f\"\\nFinal Result: {result['output']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ca0727",
   "metadata": {},
   "source": [
    "## Key Concepts Summary\n",
    "\n",
    "**What are LangChain Agents?**\n",
    "- Agents use an LLM to determine which tools to call and in what order\n",
    "- They follow a reasoning loop: Think → Act → Observe → Repeat\n",
    "- Excellent for complex multi-step tasks that require decision-making\n",
    "\n",
    "**When to use Agents:**\n",
    "- Multi-tool workflows where tool selection depends on user input\n",
    "- Tasks requiring reasoning about tool sequencing\n",
    "- Problems where the solution path isn't predetermined\n",
    "- Interactive applications needing dynamic tool usage\n",
    "\n",
    "**Common Agent Types:**\n",
    "- **ReAct Agent**: Reason + Act pattern (recommended)\n",
    "- **OpenAI Functions Agent**: For models with function-calling capabilities\n",
    "- **Conversational Agent**: For multi-turn dialogue with memory\n",
    "\n",
    "**Best Practices:**\n",
    "1. Define clear tool descriptions - agents rely on these to decide tool usage\n",
    "2. Include input validation in tools to prevent errors\n",
    "3. Use `max_iterations` to prevent infinite loops\n",
    "4. Enable `verbose=True` during development for debugging\n",
    "5. Handle parsing errors gracefully\n",
    "6. Keep tools focused and single-purpose\n",
    "7. Provide example outputs in tool descriptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
